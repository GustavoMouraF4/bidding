version: "3.7"

services:
  mongo:
    container_name: mongo
    image: mongo
    environment:
      - MONGO_INITDB_DATABASE=bidding
    ports:
      - '27017:27017'
    networks:
      - network-backend
    command: --replSet rs0
    volumes:
      - ./data:/data/db

  mongo-express:
    image: mongo-express
    environment:
      - ME_CONFIG_MONGODB_SERVER=mongo
      - ME_CONFIG_MONGODB_ENABLE_ADMIN=false
      - ME_CONFIG_MONGODB_ADMINDATABASE=bidding
      - ME_CONFIG_BASICAUTH_USERNAME=seba
      - ME_CONFIG_BASICAUTH_PASSWORD=ogato
    depends_on:
      - mongo
    networks:
      - network-backend
    ports:
      - "8888:8081"
    volumes:
      - ./data:/data/db

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    networks:
      - network-backend
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:latest
    networks:
      - network-backend
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9093,EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

  # Use localhost:9000/ to access Local Cluster
  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    container_name: kafdropLocal
    networks:
      - network-backend
    depends_on:
      - kafka
    ports:
      - 9000:9000
    environment:
      KAFKA_BROKERCONNECT: kafka:9093

  connect:
    image: confluentinc/cp-kafka-connect:6.2.0
    depends_on:
      - kafka
      - mongo
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9093
      CONNECT_GROUP_ID: "default"
      CONNECT_CONFIG_STORAGE_TOPIC: "default.config"
      CONNECT_OFFSET_STORAGE_TOPIC: "default.offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "default.status"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_REST_ADVERTISED_HOST_NAME: "default-config"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_AUTO_CREATE_TOPICS_ENABLE: "true"
    ports:
      - 8083:8083
    networks:
      - network-backend
    command:
      - bash
      - -c
      - |
        echo 'Installing Connector'
        confluent-hub install --no-prompt mongodb/kafka-connect-mongodb:1.7.0
        echo 'Launching Kafka Connect worker'
        /etc/confluent/docker/run &
        echo 'Waiting for Kafka Connect listener'
        while : ; do
          curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
          echo -e $$(date) ' Kafka Connect listener HTTP state: ' $$curl_status ' (waiting for 200)'
          if [ $$curl_status -eq 200 ] ; then
            break
          fi
          sleep 10
        done
        echo -e '\n--\n+> Creating Kafka Connector'
        sleep infinity

networks:
  network-backend:
    driver: bridge